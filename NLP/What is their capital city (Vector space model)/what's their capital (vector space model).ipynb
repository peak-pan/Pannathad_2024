{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.word_vector import WordVector\n",
    "\n",
    "from utils_vector import get_vectors\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['country', 'city', 'China', 'Iraq', 'oil', 'town', 'Canada', 'London', 'England', 'Australia', 'Japan', 'Pakistan', 'Iran', 'gas', 'happy', 'Russia', 'Afghanistan', 'France', 'Germany', 'Georgia', 'Baghdad', 'village', 'Spain', 'Italy', 'Beijing', 'Jordan', 'Paris', 'Ireland', 'Turkey', 'Egypt', 'Lebanon', 'Taiwan', 'Tokyo', 'Nigeria', 'Vietnam', 'Moscow', 'Greece', 'Indonesia', 'sad', 'Syria', 'Thailand', 'Libya', 'Zimbabwe', 'Cuba', 'Ottawa', 'Tehran', 'Sudan', 'Kenya', 'Philippines', 'Sweden', 'Poland', 'Ukraine', 'Rome', 'Venezuela', 'Switzerland', 'Berlin', 'Bangladesh', 'Portugal', 'Ghana', 'Athens', 'king', 'Madrid', 'Somalia', 'Dublin', 'Qatar', 'Chile', 'Islamabad', 'Bahrain', 'Nepal', 'Norway', 'Serbia', 'Kabul', 'continent', 'Brussels', 'Belgium', 'Uganda', 'petroleum', 'Cairo', 'Denmark', 'Austria', 'Jamaica', 'Georgetown', 'Bangkok', 'Finland', 'Peru', 'Romania', 'Bulgaria', 'Hungary', 'Vienna', 'Kingston', 'Manila', 'Cyprus', 'Azerbaijan', 'Copenhagen', 'Fiji', 'Tunisia', 'Kazakhstan', 'queen', 'Beirut', 'Jakarta', 'Croatia', 'Belarus', 'Algeria', 'Malta', 'Morocco', 'Rwanda', 'Bahamas', 'Damascus', 'Ecuador', 'Angola', 'Canberra', 'Liberia', 'Honduras', 'Tripoli', 'Slovakia', 'Doha', 'Armenia', 'Taipei', 'Oman', 'Nairobi', 'Santiago', 'Guinea', 'Uruguay', 'Stockholm', 'Slovenia', 'Zambia', 'Havana', 'Uzbekistan', 'Belgrade', 'Mogadishu', 'Khartoum', 'Botswana', 'Kyrgyzstan', 'Dhaka', 'Namibia', 'Ankara', 'Abuja', 'Lima', 'Harare', 'Warsaw', 'Malawi', 'Lisbon', 'Latvia', 'Niger', 'Lithuania', 'Estonia', 'Samoa', 'Oslo', 'Nicaragua', 'Hanoi', 'Sofia', 'Macedonia', 'Senegal', 'Mozambique', 'Guyana', 'Mali', 'Accra', 'Kathmandu', 'Tbilisi', 'Helsinki', 'Montenegro', 'Caracas', 'Laos', 'Budapest', 'Kiev', 'Turkmenistan', 'Eritrea', 'Albania', 'Madagascar', 'Nassau', 'Kampala', 'Amman', 'Greenland', 'Belize', 'Moldova', 'Burundi', 'Tajikistan', 'Baku', 'Astana', 'Gambia', 'Bucharest', 'joyful', 'Monrovia', 'Mauritania', 'Algiers', 'Muscat', 'Bern', 'Luanda', 'Dakar', 'Tunis', 'Gabon', 'Minsk', 'Liechtenstein', 'Suva', 'Yerevan', 'Zagreb', 'Bishkek', 'Manama', 'Kigali', 'Riga', 'Lusaka', 'Tashkent', 'Nicosia', 'Valletta', 'Windhoek', 'Dominica', 'Quito', 'Tallinn', 'Bratislava', 'Tegucigalpa', 'Skopje', 'Gaborone', 'Rabat', 'Maputo', 'Suriname', 'Vilnius', 'Montevideo', 'Ljubljana', 'Tirana', 'Dushanbe', 'Ashgabat', 'Asmara', 'Tuvalu', 'Managua', 'Conakry', 'Banjul', 'Bamako', 'Lilongwe', 'Vientiane', 'Chisinau', 'Roseau', 'Nouakchott', 'Podgorica', 'Niamey', 'Bujumbura', 'Apia', 'Antananarivo', 'Libreville', 'Belmopan', 'Vaduz', 'Paramaribo', 'Nuuk', 'Funafuti'])\n"
     ]
    }
   ],
   "source": [
    "a = 'เธอคือท่วงทำนองที่อ่อนหวาน เธอคือสายลมพัดยามอ่อนล้า เธอคือกาแฟในตอนเช้า ยิ่งนานวันยิ่งฉันต้องมีเธอเพิ่มเติมมากกว่า เธอคือไฟที่ให้ไออุ่นฉันในคืนที่หนาวเย็น คือคนเดียวที่อยากจะได้เห็นเมื่อฉันลืมตา ไม่เคยพอกับการได้มีเธอมาใช้ชีวิตด้วยกัน เธอคือดวงตะวัน ที่โลกฉันหมุนรอบเธอ ห้ามใจไม่ให้เจอ ไม่รู้ว่าต้องทำไง เป็นคาเฟอีนที่ฉัน ต้องการเมื่อยามเหนื่อยล้า เธอคือความหวาน ที่ดีต่อหัวใจ'\n",
    "model_th = WordVector()\n",
    "word_embeddings = pickle.load(open(\"word_embeddings_subset.p\", \"rb\"))\n",
    "print(word_embeddings.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class What_is_their_capital:\n",
    "    def __init__(self) -> None:\n",
    "        self.embedding = pickle.load(open(\"word_embeddings_subset.p\", \"rb\"))\n",
    "        self.data = pd.read_csv('capitals.txt', delimiter=' ')\n",
    "        self.accuracy = 0\n",
    "\n",
    "    def cosine_similarity(A, B):\n",
    "        dot = np.dot(A, B)  \n",
    "        norma = np.linalg.norm(A)\n",
    "        normb = np.linalg.norm(B)   \n",
    "        cos = dot/(norma*normb)\n",
    "        return cos\n",
    "    \n",
    "    def euclidean(A, B): \n",
    "        d = np.linalg.norm(A-B) \n",
    "        return d\n",
    "    \n",
    "    def get_capital(self,country1, city1, country2, cosine_similarity=cosine_similarity):\n",
    "        group = set([country1,city1,country2])\n",
    "        country1_vector = self.embedding[country1]\n",
    "        country2_vector = self.embedding[country2]\n",
    "        city1_vector = self.embedding[city1]\n",
    "        co_vector = city1_vector - country1_vector + country2_vector\n",
    "        similarity = -1\n",
    "        city = ''\n",
    "        for word in self.embedding.keys():\n",
    "            if word not in group:\n",
    "                word_vec = self.embedding[word]\n",
    "                temp_similarity = cosine_similarity(co_vector, word_vec)\n",
    "                if temp_similarity > similarity:\n",
    "                    similarity = temp_similarity\n",
    "                    city = word, similarity\n",
    "        return co_vector,city\n",
    "        \n",
    "    def get_accuracy(self):\n",
    "        num_correct = 0\n",
    "        for i, row in self.data.iterrows():\n",
    "            city1 = row[0]\n",
    "            country1 = row[1]\n",
    "            city2 = row[2]\n",
    "            country2 = row[3]\n",
    "            predicted_city2, _ = self.get_capital(country1, city1, country2)\n",
    "            if predicted_city2 == city2:\n",
    "                num_correct += 1\n",
    "\n",
    "        # get the number of rows in the data dataframe (length of dataframe)\n",
    "        m = len(self.data)\n",
    "\n",
    "        # calculate the accuracy by dividing the number correct by m\n",
    "        self.accuracy = num_correct/m\n",
    "        \n",
    "        return self.accuracy\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = What_is_their_capital()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cairo', 0.72778463)\n"
     ]
    }
   ],
   "source": [
    "co1,city1, = model.get_capital('Greece','Athens','Egypt')\n",
    "co2,city2 =  model.get_capital('Thailand','Bangkok','China')\n",
    "model.get_accuracy\n",
    "print(city1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
