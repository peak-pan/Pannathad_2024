{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from thai_tokenizer import Tokenizer \n",
    "f2 = open('sad_song.json', encoding=\"utf8\")\n",
    "f = open('songlist.json', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set preparing\n",
    "- Extract Data from JSON\n",
    "    - 5 Happy songs\n",
    "    - 5 Sad songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_happy = json.load(f)\n",
    "f.close()\n",
    "dict_sad = json.load(f2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'song1': 'เธอคือท่วงทำนองที่อ่อนหวาน เธอคือสายลมพัดยามอ่อนล้า เธอคือกาแฟในตอนเช้า ยิ่งนานวันยิ่งฉันต้องมีเธอเพิ่มเติมมากกว่า เธอคือไฟที่ให้ไออุ่นฉันในคืนที่หนาวเย็น คือคนเดียวที่อยากจะได้เห็นเมื่อฉันลืมตา ไม่เคยพอกับการได้มีเธอมาใช้ชีวิตด้วยกัน เธอคือดวงตะวัน ที่โลกฉันหมุนรอบเธอ ห้ามใจไม่ให้เจอ ไม่รู้ว่าต้องทำไง เป็นคาเฟอีนที่ฉัน ต้องการเมื่อยามเหนื่อยล้า เธอคือความหวาน ที่ดีต่อหัวใจi', 'song2': \"พี่คงจะอยู่ไม่ได้เเล้ว ถ้าไม่มีหนูคืนนี้คงนอนไม่ค่อยจะหลับ อยากคอลหาสักทีได้ไหม ตอนไหนที่หนูมีเวลา ก็คิดถึงนี่นา คิดถึงหนูที่สุด จะหยุดตัวเองยังไงก็ไม่ไหว พี่คงจะอยู่ไม่ได้แล้ว ถ้าไม่มีหนูคืนนี้ยังไงก็นอนไม่หลับ ช่วยบอกรักสักทีได้ไหม ตอนไหนที่หนูมีเวลา อย่าให้ทรมาน คิดถึงหนูทุกวัน Oh Baby you're my special one เพราะหนูสำคัญที่สุดเลย\", 'song3': 'ขออยู่ในชีวิตที่เหลือของเธอได้ไหม อยากลืมตาแล้วได้พบเธอจนวันสุดท้าย อยากเป็นคนที่ได้นอนดูดาวข้างเธออีกหมื่นวัน และเอนไปจุมพิตเธอสักล้านครั้ง อยู่กับฉันไปนาน ๆ นะเธอ', 'song4': 'ตื่นเช้ากว่าวันไหนสดใสกว่าทุกวัน ต้นไม้และลำธารก็ยังดูสดใสไม่สู้เธอ โชว์ยิ้มไปหนึ่งทียิ้มให้โลกนี้ที่กำเนิด เกิดเป็นเธอขึ้นมาให้ฉันได้เจอ วันและเวลาจะผ่านไปนานแค่ไหน แต่เธอยังเป็นคนเดียวที่ยังคงอยู่ในใจฉันไง และเธอไม่ต้องทำสงและสัย ว่ากาลเวลาจะทำให้ใจของฉันเปลี่ยนผัน ยังไงก็มีแค่เธอคนเดียวที่อยู่ในนั้นหัวใจ ให้เธออยู่ได้คนเดียวเท่านั้น', 'song5': 'ตั้งแต่วันที่ได้พบเธอก็ไม่มีดอกไม้ใดที่เจอ ที่จะสวยงาม ที่จะงดงาม เท่ารอยยิ้มของเธอ ตั้งแต่วันที่ได้พบเธอก็ไม่เคยมีคืนไหนที่ฉันจะแหงนมองดาวบนฟ้า เพราะดวงตาของเธอนั้นสวยกว่า'}\n",
      "{'song1': 'แต่เจ็บที่ต้องรู้ ว่าเธอนั้นต้องไป เจ็บที่ต้องยอมรับคำว่าเสียใจ เจ็บที่ต้องรู้ ว่าเขาคือคนใหม่ เจ็บที่วันนี้เธอรักเขาหมดหัวใจ เพราะว่ารักเธอเกินกว่าสิ่งไหน เพราะหัวใจของฉันมีไว้ให้เธอคนเดียว แม้หัวใจเธอเองไม่แลเหลียว วันนี้ฉันเป็นเพียงส่วนเกินที่เธอไม่ต้องการ', 'song2': 'เจ็บแทนเขาทุกครั้ง ทุกครั้ง ทุกครั้ง ที่ยังคงคิดถึงเธอ อ้อมกอดเขาจะแน่นเท่าไร ยังอดนึกถึงเธอไม่ได้ ผิดกับเขากี่ครั้ง กี่ครั้ง กี่ครั้ง ที่ยังซ่อนเธอเอาไว้ แม้จะลึกเท่าไร ไม่ได้ร่ำร้องให้เธอกลับมา เข้าใจดีที่ต้องเลิกรา ไม่ได้อาวรณ์ไม่โทษชะตา เดินมาไกลจากวันที่ลา แค่เพียงเสี้ยวนาที ของในบางราตรี ได้ยินเสียงของเธอในยามนิทรา', 'song3': 'แต่ยิ่งรักก็ยิ่งจะทรมาน พยายามจะหลบแล้ว พยายามจะหลีกแล้ว แต่ก็ยังไม่แคล้วรักเธออีกครั้ง พยายามจะหยุดพัก พยายามจะหยุดรัก แต่มันยากนักที่จะหยุดรัก ยิ่งพยายามยังไงในใจมันร้องตะโกน โอ้ย ใจมันเจ็บ ใจมันปวด ใจมันรวด ใจมันร้าว ใจมันร้องตะโกน อ๊าว เจ็บนี้อีกยาว ถ้ารักแล้วมันต้องฝืน ฉันก็คงไม่ขืน เลิกแสดง', 'song4': 'เลือกเขา และทิ้งฉันไว้ตรงกลางทาง เมื่อตัวเธอพบคนที่ดี ที่เธอวาดไว้ในหัวใจ ปล่อยมือฉันถูกแล้ว ให้ใจของฉันปวดร้าวแค่ไหน ยอมฝืนใจให้เธอ เดินจากฉันไป เมื่อรู้ว่าเธอ มีคนที่พาไปถึงปลายทาง ความจริงที่ฉันกลัว กลัวการไม่มีเธอ กลัวถึงวันนี้มาเนิ่นนาน เพียงคำว่ารักเธอ มันคงไม่เพียงพอ ให้รั้งเธอไว้ไม่ได้เลย เมื่อเธอจะไปก็เข้าใจ เมื่อเธอเจอใครดีกว่ามากมาย คงไม่ต้องรอ', 'song5': 'คือฉันนั้นเป็นคนผิดเอง ผิดและพลั้งพลาดไป เสียจนใจเธอเริ่มทนไม่ไหว (ทนไม่ไหว ทนไม่ไหว) เมื่อวันนี้เธอมีคำบอกลา ส่วนตัวฉันก็มีคำหนึ่งคำที่ไม่เคยพูดไป จะบอกเธอในวันนี้ คือฉันเสียใจ ที่ฉันชอบทำผิดไปทุกที ความคิดไม่ตรงกับใจสักที ถ้าหากยังเป็นคนแบบนี้ ไม่รู้ว่าเธอจะยังเข้าใจกันบ้างไหม ถ้าหากความผิดที่ฉันทำ มันย้ำให้เธอต้องเสียใจ มันย้ำให้เธอต้องร้องไห้ ขอโทษจากหัวใจ แต่จะให้ดีกว่านี้ก็คงไม่ไหวจริงจริง'}\n"
     ]
    }
   ],
   "source": [
    "print(dict_happy)\n",
    "print(dict_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_song = []\n",
    "sad_song = []\n",
    "for i in dict_happy:\n",
    "    happy_song.append(dict_happy[i])\n",
    "for j in dict_sad:\n",
    "    sad_song.append(dict_sad[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = happy_song[:4] + sad_song[:4]\n",
    "test_set = happy_song[4:] + sad_song[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.append(np.ones((len(happy_song[:4]), 1)), np.zeros((len(sad_song[:4]), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(happy_song[4:]), 1)), np.zeros((len(sad_song[4:]), 1)), axis=0)\n",
    "train_y2 = np.squeeze(train_y)\n",
    "test_y2 = np.squeeze(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() #declared Thai Tokenizer as tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions.\n",
    "- Process (get rid of unnecessary  characters or symbols) \\n\n",
    "- build_freq (create frequency dictionary of positvie and negative word appear in dataset)  - [(word,1):frequency] (positive) and [(word,0):frequency] (negative)\n",
    "- sigmoid (logistic function result in range (0,1))\n",
    "- gradient descent (reducing cost function)\n",
    "- extract_features (convert word to vector using frequency dictionary)\n",
    "- vectorized (convert all of word in dataset to vector [bias(1), positive_count, negative_count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(sentence):\n",
    "    i= re.sub(r'[(,)]', '', sentence)\n",
    "    x = tokenizer(i)\n",
    "    arr = x.split(' ')\n",
    "    return arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_freq(y,x):\n",
    "    freqs = {}\n",
    "    for yi,xi in zip(y,x):\n",
    "        for word in Process(xi):\n",
    "            pair = (word, yi)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] +=1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "    return freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    m = x.shape[0]\n",
    "\n",
    "    for i in range(0, num_iters):\n",
    "        z = np.dot(x, theta)\n",
    "        h = sigmoid(z)\n",
    "        J = -1/m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))\n",
    "        theta += -(alpha/m)*(np.dot(x.transpose(),(h-y)))\n",
    "        #print(\"epoch:\", i,\" Cost:\", J)\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(song, freqs, Process=Process):\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = Process(song)\n",
    "    x = np.zeros(3)  # 3 elements for [bias, positive, negative] counts\n",
    "    x[0] = 1  # bias term is set to 1\n",
    "\n",
    "    for word in word_l:\n",
    "        x[1] += freqs.get((word, 1), 0) \n",
    "        x[2] += freqs.get((word, 0), 0)    \n",
    "    \n",
    "    x = x[None, :]  # adding batch dimension for further processing\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorized(X, freqs_dict,extract_features=extract_features):\n",
    "    a = []\n",
    "    for w in X: \n",
    "        x = extract_features(w, freqs_dict)\n",
    "        a.append(x[0])\n",
    "    a = np.array(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Is_this_a_sad_song:\n",
    "\n",
    "    def __init__(self,train_X, train_Y, test_X, test_Y) -> None:\n",
    "        self.X_train = train_X\n",
    "        self.Y_train = train_Y\n",
    "        self.X_test = test_X\n",
    "        self.Y_test = test_Y\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.freqs_dict = build_freq(train_y2,train_X)\n",
    "        self.theta = np.zeros((3, 1))\n",
    "        self.J = 0\n",
    "    \n",
    "    def train(self):\n",
    "        x = Vectorized(self.X_train,self.freqs_dict)\n",
    "        J, theta = gradientDescent(x, train_y, np.zeros((3, 1)), 9e-6, 1500)\n",
    "        self.J = J\n",
    "        self.theta = theta\n",
    "\n",
    "        return self.J,self.theta\n",
    "    \n",
    "    def predict(self,word):\n",
    "        word_vector = extract_features(word, self.freqs_dict)\n",
    "        y_predict = sigmoid(np.dot(word_vector,self.theta))\n",
    "        if y_predict >= 0.5:\n",
    "            return 'is not a sad song :)'\n",
    "        else:\n",
    "            return 'is a sad song :('\n",
    "        \n",
    "    def accuracy(self,predict=predict):\n",
    "        y_hat = list()\n",
    "        for song in self.X_test:\n",
    "            y_pred = predict(song, self.freqs_dict, self.theta)\n",
    "            if y_pred > 0.5:\n",
    "                y_hat.append(1.0)\n",
    "            else:\n",
    "                y_hat.append(0.0)\n",
    "        accuracy = sum(np.squeeze(self.Y_test) == y_hat)/(len(self.X_test))\n",
    "        print(accuracy)\n",
    "        return accuracy       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE TRAINING 1: LOSS = 0 2: theta = [[0. 0. 0.]]\n",
      "POST TRAINING 1: LOSS = 0.013224808143444549 2: theta = [[ 7.84087286e-05  3.80549117e-02 -3.58372945e-02]]\n",
      "accuracy = <bound method Is_this_a_sad_song.accuracy of <__main__.Is_this_a_sad_song object at 0x0000020A9F65BD90>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peaks\\AppData\\Local\\Temp\\ipykernel_14424\\3211945146.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    }
   ],
   "source": [
    "MODEL = Is_this_a_sad_song(train_set,train_y,test_set,test_y)\n",
    "print(\"PRE TRAINING 1: LOSS =\",MODEL.J,\"2: theta =\",MODEL.theta.T)\n",
    "MODEL.train()\n",
    "print(\"POST TRAINING 1: LOSS =\",MODEL.J,\"2: theta =\",MODEL.theta.T)\n",
    "print(\"accuracy =\",MODEL.accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = 'ก็ฉันเมื่อรักใครก็ต้องเป็นคนผิดหวัง'\n",
    "pred2 = 'เธอคือหวานเย็น ดับร้อนข้างในหัวใจที่ฉันมี'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyric : ก็ฉันเมื่อรักใครก็ต้องเป็นคนผิดหวัง is a sad song :(\n",
      "Lyric : เธอคือหวานเย็น ดับร้อนข้างในหัวใจที่ฉันมี is not a sad song :)\n"
     ]
    }
   ],
   "source": [
    "print(\"Lyric :\",pred1,MODEL.predict(pred1))\n",
    "print(\"Lyric :\",pred2,MODEL.predict(pred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
