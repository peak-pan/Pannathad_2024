{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\peaks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\peaks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences : 3914\n",
      "Tagged words : 100676\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences :\", len(tagged_sentences))\n",
    "print(\"Tagged words :\", len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(tagged_sentences):\n",
    "    sentences, sentence_tags = [], []\n",
    "    for tagged_sentence in tagged_sentences:\n",
    "        sentence, tags = zip(*tagged_sentence)\n",
    "        sentences.append(np.array(sentence))\n",
    "        sentence_tags.append(np.array(tags))\n",
    "    return sentences, sentence_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = prepare(tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = set([]), set([])\n",
    "\n",
    "for s in X_train:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "\n",
    "for ts in y_train:\n",
    "    for t in ts:\n",
    "        tags.add(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE WORD INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {w: i for i,w in enumerate(list(words),2)}\n",
    "word2index['-PAD-'] = 0\n",
    "word2index['-OOV-'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2index = {t: i for i, t in enumerate(list(tags),1)}\n",
    "tag2index['-PAD-'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE INDEX VECTOR WITH PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = [],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2index(sentence):\n",
    "    result = []\n",
    "    for s in sentence:\n",
    "        s_int = []\n",
    "        for w in s:\n",
    "            try:\n",
    "                s_int.append(word2index[w.lower()])\n",
    "            except KeyError:\n",
    "                s_int.append(word2index['-OOV-'])\n",
    "        result.append(s_int)\n",
    "    return result\n",
    "def t2index(tagging):\n",
    "    result = []\n",
    "    for s in tagging:\n",
    "        sss = []\n",
    "        for t in s:\n",
    "            sss.append(tag2index[t])\n",
    "        result.append(sss)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153, 7801, 7190, 6586, 8480, 5056, 5840, 2962, 3675, 230, 9955, 5090, 7278, 5466, 7190, 7661, 5419, 5141]\n",
      "[1931, 904, 3724, 1160, 5141]\n",
      "[39, 39, 31, 20, 36, 3, 40, 24, 29, 4, 33, 21, 17, 36, 31, 36, 36, 44]\n",
      "[29, 3, 40, 4, 44]\n"
     ]
    }
   ],
   "source": [
    "train_X = w2index(X_train)\n",
    "test_X = w2index(X_test)\n",
    "train_y = t2index(y_train)\n",
    "test_y = t2index(y_test)\n",
    "print(train_X[0])\n",
    "print(test_X[0])\n",
    "print(train_y[0])\n",
    "print(test_y[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    }
   ],
   "source": [
    "Max_length = len(max(train_X, key=len))\n",
    "print(Max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "train_X = pad_sequences(train_X,maxlen=Max_length,padding='post')\n",
    "test_X = pad_sequences(test_X,maxlen=Max_length,padding='post')\n",
    "train_y = pad_sequences(train_y,maxlen=Max_length,padding='post')\n",
    "test_y = pad_sequences(test_y,maxlen=Max_length,padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 153 7801 7190 6586 8480 5056 5840 2962 3675  230 9955 5090 7278 5466\n",
      " 7190 7661 5419 5141    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(Max_length,)),\n",
    "        Embedding(len(word2index),128),\n",
    "        Bidirectional(LSTM(256, return_sequences=True)),\n",
    "        TimeDistributed(Dense(len(tag2index))),\n",
    "        Activation('softmax')\n",
    "    ] \n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 271, 128)          1301376   \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirecti  (None, 271, 512)          788480    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDi  (None, 271, 47)           24111     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 271, 47)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2113967 (8.06 MB)\n",
      "Trainable params: 2113967 (8.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "271\n",
      "271\n"
     ]
    }
   ],
   "source": [
    "print(len(tag2index))\n",
    "print(len(train_y[0]))\n",
    "print(len(train_X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categortical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_y_train = np.array(to_categortical(train_y, len(tag2index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\peaks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\peaks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "25/25 [==============================] - 24s 806ms/step - loss: 1.0235 - accuracy: 0.8688\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 28s 1s/step - loss: 0.3247 - accuracy: 0.9051\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 28s 1s/step - loss: 0.3086 - accuracy: 0.9154\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 29s 1s/step - loss: 0.2981 - accuracy: 0.9163\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.2890 - accuracy: 0.9170\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 30s 1s/step - loss: 0.2799 - accuracy: 0.9206\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2733 - accuracy: 0.9247\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.2664 - accuracy: 0.9298\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2558 - accuracy: 0.9351\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2367 - accuracy: 0.9425\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2068 - accuracy: 0.9484\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1718 - accuracy: 0.9536\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1391 - accuracy: 0.9631\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1104 - accuracy: 0.9727\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.0864 - accuracy: 0.9804\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0668 - accuracy: 0.9860\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.0516 - accuracy: 0.9896\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0406 - accuracy: 0.9919\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0270 - accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17ef2cb98d0>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X,cat_y_train,batch_size=128,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 83ms/step - loss: 0.0401 - accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "cat_y_test = np.array(to_categortical(test_y, len(tag2index)))\n",
    "scores = model.evaluate(test_X,cat_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:99.04521107673645%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{model.metrics_names[1]}:{scores[1]*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['He', 'reads', 'many', 'books', 'in', 'the', 'library'], ['Although', 'she', 'completed', 'her', 'literature', 'review']]\n"
     ]
    }
   ],
   "source": [
    "test = [\"He reads many books in the library\".split(),\"Although she completed her literature review\".split()]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = w2index(test)\n",
    "padded_sample = pad_sequences(sample,maxlen=Max_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 684ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(padded_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.8640072e-03 4.4722561e-04 3.5835899e-05 ... 2.1408070e-04\n",
      "   9.6128148e-04 7.4752490e-04]\n",
      "  [4.5205005e-02 5.5212267e-03 7.0775985e-03 ... 8.3648181e-04\n",
      "   9.4772261e-03 1.5221503e-02]\n",
      "  [7.3485631e-03 1.7491283e-03 3.3296183e-02 ... 5.4759999e-05\n",
      "   3.4532154e-03 8.9769540e-03]\n",
      "  ...\n",
      "  [9.9992001e-01 4.3011880e-07 1.1311869e-09 ... 2.1744210e-05\n",
      "   2.1017263e-09 7.4617628e-09]\n",
      "  [9.9987280e-01 6.9727122e-07 1.7467490e-09 ... 2.3579663e-05\n",
      "   3.2616077e-09 1.2133955e-08]\n",
      "  [9.9981087e-01 1.0384198e-06 2.4860405e-09 ... 2.3846491e-05\n",
      "   4.7196109e-09 1.8633127e-08]]\n",
      "\n",
      " [[1.8216176e-03 2.2501107e-03 1.6676892e-02 ... 1.2285743e-06\n",
      "   5.1843049e-03 2.1493409e-02]\n",
      "  [9.0344646e-04 5.9950794e-04 9.8472621e-05 ... 1.1074911e-04\n",
      "   2.7836266e-03 1.0340712e-03]\n",
      "  [3.2397746e-03 2.1991485e-03 2.0707571e-03 ... 6.9810456e-05\n",
      "   6.3462229e-03 2.4792381e-02]\n",
      "  ...\n",
      "  [9.9992001e-01 4.3011755e-07 1.1311913e-09 ... 2.1744398e-05\n",
      "   2.1017343e-09 7.4617770e-09]\n",
      "  [9.9987280e-01 6.9726855e-07 1.7467523e-09 ... 2.3579843e-05\n",
      "   3.2616139e-09 1.2133955e-08]\n",
      "  [9.9981087e-01 1.0384177e-06 2.4860500e-09 ... 2.3846718e-05\n",
      "   4.7196376e-09 1.8633234e-08]]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for cat_seq in sequences:\n",
    "        token_sequence = []\n",
    "        for cat in cat_seq:\n",
    "            token_sequence.append(index[np.argmax(cat)])\n",
    "\n",
    "        token_sequences.append(token_sequence)\n",
    "    return token_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = logits_to_tokens(prediction,{i:t for t,i in tag2index.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Although', 'she', 'completed', 'her', 'literature', 'review']\n",
      "['IN', 'PRP', 'VBD', 'PRP$', 'NN', 'NN']\n"
     ]
    }
   ],
   "source": [
    "print(test[1])\n",
    "print(answer[:len(sample[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
